@book{Gelman1995,
  title={Bayesian data analysis},
  author={Gelman, Andrew and Carlin, John B and Stern, Hal S and Rubin, Donald B},
  year={1995},
  publisher={Chapman and Hall/CRC}
}
@article{Chen1992,
   author = {Ming-Hui Chen and Bruce W. Schmeiser},
   doi = {10.1080/10618600.1993.10474611},
   issue = {September 1993},
   journal = {Journal of Computational and Graphical Statistics},
   pages = {1-28},
   title = {Performance of the Gibbs , Hit-and-Run , and Metropolis Samplers},
   year = {1992},
}
@article{Vasilios1999,
   abstract = {Detailed balance is an overly strict condition to ensure a valid Monte Carlo simulation. We show that, under fairly general assumptions, a Monte Carlo simulation need satisfy only the weaker balance condition. Not only does our proof show that sequential updating schemes are correct, but also it establishes the correctness of a whole class of new methods that simply leave the Boltzmann distribution invariant. © 1999 American Institute of Physics.},
   author = {Vasilios I. Manousiouthakis and Michael W. Deem},
   doi = {10.1063/1.477973},
   issn = {00219606},
   issue = {2-12},
   journal = {Journal of Chemical Physics},
   month = {2},
   pages = {2753-2756},
   publisher = {American Institute of Physics Inc.},
   title = {Strict detailed balance is unnecessary in Monte Carlo simulation},
   volume = {110},
   year = {1999},
}
@article{Haario2001,
   abstract = {A proper choice of a proposal distribution for Markov chain Monte Carlo methods, for example for the Metropolis-Hastings algorithm, is well known to be a crucial factor for the convergence of the algorithm. In this paper we introduce an adaptive Metropolis (AM) algorithm, where the Gaussian proposal distribution is updated along the process using the full information cumulated so far. Due to the adaptive nature of the process, the AM algorithm is non-Markovian, but we establish here that it has the correct ergodic properties. We also include the results of our numerical tests, which indicate that the AM algorithm competes well with traditional Metropolis-Hastings algorithms, and demonstrate that the AM algorithm is easy to use in practical computation.},
   author = {Heikki Haario and Eero Saksman and Johanna Tamminen},
   doi = {10.2307/3318737},
   issn = {13507265},
   issue = {2},
   journal = {Bernoulli},
   keywords = {adaptive markov chain monte,carlo,comparison,convergence,ergodicity,hastings algorithm,markov chain,metropolis,monte carlo},
   pages = {223},
   title = {An Adaptive Metropolis Algorithm},
   volume = {7},
   year = {2001},
}
@article{Qian2003,
   abstract = {Bayesian methods are experiencing increased use for probabilistic ecological modelling. Most Bayesian inference requires the numerical approximation of analytically intractable integrals. Two methods based on Monte Carlo simulation have appeared in the ecological/environmental modelling literature. Though they sound similar, the Bayesian Monte Carlo (BMC) and Markov Chain Monte Carlo (MCMC) methods are very different in their efficiency and effectiveness in providing useful approximations for accurate inference in Bayesian applications. We compare these two methods using a low-dimensional biochemical oxygen demand decay model as an example. We demonstrate that the BMC is extremely inefficient because the prior parameter distribution, from which the Monte Carlo sample is drawn, is often a poor surrogate for the posterior parameter distribution, particularly if the parameters are highly correlated. In contrast, MCMC generates a chain that converges, in distribution, on the posterior parameter distribution, that can be regarded as a sample from the posterior distribution. The inefficiency of the BMC can lead to marginal posterior parameter distributions that appear irregular and may be highly misleading because the important region of the posterior distribution may never be sampled. We also point out that a priori specification of the model error variance can strongly influence the estimation of the principal model parameters. Although the BMC does not require that the model error variance be specified, most published applications have treated this variance as a known constant. Finally, we note that most published BMC applications have chosen a uniform prior distribution, making the BMC more similar to a likelihood-based inference rather than a Bayesian method because the posterior is unaffected by the prior. Though other prior distributions could be applied, the treatment of Monte Carlo samples with any other choice of prior distribution has not been discussed in the BMC literature.},
   author = {Song S Qian and Craig A Stow and Mark E Borsuk},
   journal = {Ecological Modelling},
   keywords = {Biochemical oxygen demand,MCMC,Uncertainty analysis,WinBUGS},
   pages = {269-277},
   title = {On Monte Carlo methods for Bayesian inference},
   volume = {159},
   url = {www.elsevier.com/locate/ecolmodel},
   year = {2003},
}
@article{TerBraak2006,
   abstract = {Differential Evolution (DE) is a simple genetic al- gorithm for numerical optimization in real parameter spaces. In a statistical context one would not just want the optimum but also its uncertainty. The uncertainty distribution can be obtained by a Bayesian analysis (after specifying prior and likelihood) using Markov Chain Monte Carlo (MCMC) sim- ulation. This paper integrates the essential ideas of DE and MCMC, resulting in Differential Evolution Markov Chain (DE-MC). DE-MC is a population MCMC algorithm, in which multiple chains are run in parallel. DE-MC solves an important problem inMCMC,namely that of choosing an appropriate scale and orientation for the jumping distribu- tion. In DE-MC the jumps are simply a fixed multiple of the differences of two random parameter vectors that are cur- rently in the population. The selection process of DE-MC works via the usual Metropolis ratio which defines the prob- ability with which a proposal is accepted. In tests with known uncertainty distributions, the efficiency of DE-MC with re- spect to random walk Metropolis with optimal multivariate Normal jumps ranged from 68% for small population sizes to 100% for large population sizes and even to 500% for the 97.5% point of a variable from a 50-dimensional Student distribution. Two Bayesian examples illustrate the potential of DE-MC in practice. DE-MC is shown to facilitate mul- tidimensional updates in a multi-chain “Metropolis-within- Gibbs” sampling approach. The advantage of DE-MC over conventionalMCMCare simplicity, speed of calculation and convergence, even for nearly collinear parameters and mul- timodal densities.},
   author = {Cajo J. F. Ter Braak},
   doi = {10.1007/s11222-006-8769-1},
   issn = {0960-3174},
   issue = {3},
   journal = {Statistics and Computing},
   keywords = {block updating,carlo,evolutionary monte carlo,metropolis algorithm,population markov chain monte,simulated annealing,simulated tempering,theophylline kinetics},
   pages = {239-249},
   title = {A Markov Chain Monte Carlo version of the genetic algorithm Differential Evolution: easy Bayesian computing for real parameter spaces},
   volume = {16},
   year = {2006},
}
@article{Demyanov2006,
   abstract = {Population dynamic modelling often entails parameterizing quite sophisticated biological and ecological mechanisms. For models of moderate mechanistic complexity, this has traditionally been done in an ad hoc manner, with different parameters being estimated independently. The point estimates so obtained are then used for model simulation, perhaps with some further ad hoc adjustment based on comparison with any available data on population dynamics. Quantitative assessments of model adequacy and prediction uncertainty are not easily made using this approach. As an alternative, the paper investigates the practical feasibility of fitting a moderately complex population dynamic model directly and simultaneously to all the data available for parameterization of the model, and to all available data on the population dynamics of the target animal. This alternative approach allows us to combine all available quantitative information on the target species, to assess the viability of the model, the mutual consistency of model and different sources of data and to estimate the uncertainties that are associated with model-based predictions. The target organism in this study is the freshwater amphipod Gammarus pulex (L.), which we model using a stage-structured population dynamic model, implemented via a set of delay differential equations describing the basic demography of the population. Target data include population dynamic data from two sites, information on basic physiological relationships and environmental temperature data. Fitting is performed by using a non-linear least squares approach supplemented with a bootstrapping method for avoiding small scale local minima in the least squares objective function. Variance estimation is performed by further bootstrapping. Interest in Gammarus pulex population dynamics in this case is primarily related to likely population level responses to chemical stressors, and for this we examine predicted 'recovery times' following exposure to a known toxicant. © 2006 Royal Statistical Society.},
   author = {V. Demyanov and S. N. Wood and T. J. Kedwards},
   doi = {10.1111/j.1467-9876.2005.00527.x},
   issn = {00359254},
   issue = {1},
   journal = {Journal of the Royal Statistical Society. Series C: Applied Statistics},
   keywords = {Differential equation model,Ecological prediction,Ecological risk assessment,Population dynamic model},
   pages = {41-62},
   title = {Improving ecological impact assessment by statistical data synthesis using process-based models},
   volume = {55},
   year = {2006},
}
@article{Haario2006,
   abstract = {We propose to combine two quite powerful ideas that have recently appeared in the Markov chain Monte Carlo literature: adaptive Metropolis samplers and delayed rejection. The ergodicity of the resulting non-Markovian sampler is proved, and the efficiency of the combination is demonstrated with various examples. We present situations where the combination outperforms the original methods: adaptation clearly enhances efficiency of the delayed rejection algorithm in cases where good proposal distributions are not available. Similarly, delayed rejection provides a systematic remedy when the adaptation process has a slow start. © Springer Science + Business Media, LLC 2006.},
   author = {Heikki Haario and Marko Laine and Antonietta Mira and Eero Saksman},
   doi = {10.1007/s11222-006-9438-0},
   issn = {09603174},
   issue = {4},
   journal = {Statistics and Computing},
   keywords = {Adaptive Markov chain Monte Carlo,Adaptive Metropolis-Hastings,Delayed rejection,Efficiency ordering},
   month = {12},
   pages = {339-354},
   title = {DRAM: Efficient adaptive MCMC},
   volume = {16},
   year = {2006},
}
@article{TerBraak2008,
   abstract = {Differential Evolution Markov Chain (DE-MC) is an adaptive MCMC algorithm, in which multiple chains are run in parallel. Standard DE-MC requires at least N=2d chains to be run in parallel, where d is the dimensionality of the posterior. This paper extends DE-MC with a snooker updater and shows by simulation and real examples that DE-MC can work for d up to 50-100 with fewer parallel chains (e.g. N=3) by exploiting information from their past by generating jumps from differences of pairs of past states. This approach extends the practical applicability of DE-MC and is shown to be about 5-26 times more efficient than the optimal Normal random walk Metropolis sampler for the 97.5% point of a variable from a 25-50 dimensional Student t (3) distribution. In a nonlinear mixed effects model example the approach outperformed a block-updater geared to the specific features of the model.},
   author = {Cajo J.F. Ter Braak and Jasper A. Vrugt},
   doi = {10.1007/s11222-008-9104-9},
   issn = {09603174},
   issue = {4},
   journal = {Statistics and Computing},
   keywords = {Adaptive Markov chain Monte Carlo,Adaptive direction sampling,Differential evolution,Evolutionary Monte Carlo,Metropolis algorithm,Parallel computing,Theophylline kinetics},
   pages = {435-446},
   title = {Differential Evolution Markov Chain with snooker updater and fewer chains},
   volume = {18},
   year = {2008},
}
@article{Vrugt2009,
   abstract = {Markov chain Monte Carlo (MCMC) methods have found widespread use in many fields of study to estimate the average properties of complex systems, and for posterior inference in a Bayesian framework. Existing theory and experiments prove convergence of well constructed MCMC schemes to the appropriate limiting distribution under a variety of different conditions. In practice, however this convergence is often observed to be disturbingly slow. This is frequently caused by an inappropriate selection of the proposal distribution used to generate trial moves in the Markov Chain. Here we show that significant improvements to the efficiency of MCMC simulation can be made by using a self-adaptive Differential Evolution learning strategy within a population-based evolutionary framework. This scheme, entitled DiffeRential Evolution Adaptive Metropolis or DREAM, runs multiple different chains simultaneously for global exploration, and automatically tunes the scale and orientation of the proposal distribution in randomized subspaces during the search. Ergodicity of the algorithm is proved, and various examples involving nonlinearity, high-dimensionality, and multimodality show that DREAM is generally superior to other adaptive MCMC sampling approaches. The DREAM scheme significantly enhances the applicability of MCMC simulation to complex, multi-modal search problems.},
   author = {J. A. Vrugt and C. J. F. ter Braak and C. G. H. Diks and B. A. Robinson and J. M. Hyman and D. Higdon},
   doi = {10.2307/j.ctt1ffjgnb.124},
   journal = {International Journal of Nonlinear Sciences and Numerical Simulation},
   pages = {176-177},
   title = {Accelerating Markov Chain Monte Carlo Simulation by Differential Evolution with Self-Adaptive Randomized Subspace Sampling},
   volume = {836},
   year = {2009},
}
@article{Roberts2007,
   abstract = {We consider basic ergodicity properties of adaptive Markov chain Monte Carlo algorithms under minimal assumptions, using coupling constructions. We prove convergence in distribution and a weak law of large numbers. We also give counterexamples to demonstrate that the assumptions we make are not redundant.},
   author = {Gareth Roberts and Jeffrey Rosenthal},
   issue = {2},
   journal = {Journal of Applied Probability},
   keywords = {2000 mathematics subject classification,65c40,computational methods,markov chains,primary 60j10,secondary 60j22},
   pages = {458-475},
   title = {Coupling and Ergodicity of Adaptive Markov Chain Monte Carlo Algorithms},
   volume = {44},
   year = {2012},
}
@article{Turner2012,
   abstract = {Approximate Bayesian computation (ABC) is a simulation-based method for estimating the posterior distribution of the parameters of a model. The ABC approach is instrumental when a likelihood function for a model cannot be mathematically specified, or has a complicated form. Although difficulty in calculating a model's likelihood is extremely common, current ABC methods suffer from two problems that have largely prevented their mainstream adoption: long computation time and an inability to scale beyond a few parameters. We introduce differential evolution as a computationally efficient genetic algorithm for proposal generation in our ABC sampler. We show how using this method allows our new ABC algorithm, called ABCDE, to obtain accurate posterior estimates in fewer iterations than kernel-based ABC algorithms and to scale to high-dimensional parameter spaces that have proven difficult for current ABC methods. © 2012 Elsevier Inc..},
   author = {Brandon M. Turner and Per B. Sederberg},
   doi = {10.1016/j.jmp.2012.06.004},
   issn = {00222496},
   issue = {5},
   journal = {Journal of Mathematical Psychology},
   keywords = {Approximate Bayesian computation,Computational modeling,Differential evolution,Likelihood-free inference},
   month = {10},
   pages = {375-385},
   title = {Approximate Bayesian computation with differential evolution},
   volume = {56},
   year = {2012},
}
@article{Turner2013,
   abstract = {Bayesian estimation has played a pivotal role in the understanding of individual differences. However, for many models in psychology, Bayesian estimation of model parameters can be difficult. One reason for this difficulty is that conventional sampling algorithms, such as Markov chain Monte Carlo (MCMC), can be inefficient and impractical when little is known about the target distribution--particularly the target distribution's covariance structure. In this article, we highlight some reasons for this inefficiency and advocate the use of a population MCMC algorithm, called differential evolution Markov chain Monte Carlo (DE-MCMC), as a means of efficient proposal generation. We demonstrate in a simulation study that the performance of the DE-MCMC algorithm is unaffected by the correlation of the target distribution, whereas conventional MCMC performs substantially worse as the correlation increases. We then show that the DE-MCMC algorithm can be used to efficiently fit a hierarchical version of the linear ballistic accumulator model to response time data, which has proven to be a difficult task when conventional MCMC is used.},
   author = {Brandon M. Turner and Per B. Sederberg and Scott D. Brown and Mark Steyvers},
   doi = {10.1037/a0032222},
   issn = {1082989X},
   issue = {3},
   journal = {Psychological Methods},
   keywords = {Differential evolution,Hierarchical Bayesian estimation,Linear ballistic accumulator model,Optimal transition kernel,Response time},
   pages = {368-384},
   title = {A Method for efficiently sampling from distributions with correlated dimensions},
   volume = {18},
   year = {2013},
}
@article{Jabot2013,
   abstract = {Approximate Bayesian computation (ABC), a type of likelihood-free inference, is a family of statistical techniques to perform parameter estimation and model selection. It is increasingly used in ecology and evolution, where the models used can be too complex to be handled with standard likelihood techniques. The essence of ABC techniques is to compare simulation outputs to observed data, in order to select the parameter values of the simulations which best fit the data. ABC techniques are thus computationally demanding. This constitutes a key limitation to their implementation. We introduce the R package 'EasyABC' that enables one to launch a series of simulations from the R platform and to retrieve the simulation outputs in an appropriate format for post-processing. The 'EasyABC' package further implements several efficient parameter sampling schemes to speed up the ABC procedure: on top of the standard prior sampling, it implements various algorithms to perform sequential (ABC-sequential) and Markov chain Monte Carlo (ABC-MCMC) sampling schemes. The package functions can furthermore make use of parallel computing. The R package 'EasyABC' complements the package 'abc' which enables various post-processing of simulation outputs. 'EasyABC' makes several state-of-the-art ABC implementations available to the large community of R users in the fields of ecology and evolution. It is a freely available R package under the GPL license, and it can be downloaded at http://cran.r-project.org/web/packages/EasyABC/index.html. © 2013 British Ecological Society.},
   author = {Franck Jabot and Thierry Faure and Nicolas Dumoulin},
   doi = {10.1111/2041-210X.12050},
   issn = {2041210X},
   issue = {7},
   journal = {Methods in Ecology and Evolution},
   keywords = {Approximate Bayesian computation,Markov chain Monte Carlo,Model selection,Model-based inference,Parameter estimation,Sequential Monte Carlo},
   month = {7},
   pages = {684-687},
   title = {EasyABC: Performing efficient approximate Bayesian computation sampling schemes using R},
   volume = {4},
   year = {2013},
}
@article{Allison2014,
   abstract = {The posterior probability distribution for a set of model parameters encodes all that the data have to tell us in the context of a given model; it is the fundamental quantity for Bayesian parameter estimation. In order to infer the posterior probability distribution we have to decide how to explore parameter space. Here we compare three prescriptions for how parameter space is navigated, discussing their relative merits. We consider Metropolis-Hasting sampling, nested sampling and affine-invariant ensemble MCMC sampling. We focus on their performance on toy-model Gaussian likelihoods and on a real-world cosmological data set. We outline the sampling algorithms themselves and elaborate on performance diagnostics such as convergence time, scope for parallelisation, dimensional scaling, requisite tunings and suitability for non-Gaussian distributions. We find that nested sampling delivers high-fidelity estimates for posterior statistics at low computational cost, and should be adopted in favour of Metropolis-Hastings in many cases. Affine-invariant MCMC is competitive when computing clusters can be utilised for massive parallelisation. Affine-invariant MCMC and existing extensions to nested sampling naturally probe multi-modal and curving distributions.},
   author = {Rupert Allison and Joanna Dunkley},
   doi = {10.1093/mnras/stt2190},
   issn = {00358711},
   issue = {4},
   journal = {Monthly Notices of the Royal Astronomical Society},
   keywords = {Methods,Statistical-cosmological parameters},
   pages = {3918-3928},
   title = {Comparison of sampling techniques for bayesian parameter estimation},
   volume = {437},
   year = {2014},
}
@book{Kruschke2014,
   author = {John Kruschke},
   edition = {2},
   title = {Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan},
   year = {2014},
}
@book{Hobbs2015,
   author = {N Thompson Hobbs and Mevin B Hooten},
   city = {Princeton},
   doi = {doi:10.1515/9781400866557},
   isbn = {9781400866557},
   publisher = {Princeton University Press},
   title = {A Statistical Primer for Ecologists},
   url = {https://doi.org/10.1515/9781400866557},
   year = {2015},
}
@article{Strathmann2015,
   abstract = {We propose Kernel Hamiltonian Monte Carlo (KMC), a gradient-free adaptive MCMC algorithm based on Hamiltonian Monte Carlo (HMC). On target densities where classical HMC is not an option due to intractable gradients, KMC adap-tively learns the target's gradient structure by fitting an exponential family model in a Reproducing Kernel Hilbert Space. Computational costs are reduced by two novel efficient approximations to this gradient. While being asymptotically exact, KMC mimics HMC in terms of sampling efficiency, and offers substantial mixing improvements over state-of-the-art gradient free samplers. We support our claims with experimental studies on both toy and real-world applications, including Approximate Bayesian Computation and exact-approximate MCMC.},
   author = {Heiko Strathmann and Dino Sejdinovic and Samuel Livingstone and Zoltan Szabo and Arthur Gretton},
   journal = {arXiv},
   pages = {1-9},
   title = {Gradient-free Hamiltonian Monte Carlo with Efficient Kernel Exponential Families},
   url = {https://github.com/karlnapf/kernel_hmc},
   year = {2015},
}
@article{Kennedy2015,
   abstract = {When Markov chain Monte Carlo (MCMC) algorithms are used with complex mechanistic models, convergence times are often severely compromised by poor mixing rates and a lack of computational power. Methods such as adaptive algorithms have been developed to improve mixing, but these algorithms are typically highly sophisticated, both mathematically and computationally. Here we present a nonadaptive MCMC algorithm, which we term line-search MCMC, that can be used for efficient tuning of proposal distributions in a highly parallel computing environment, but that nevertheless requires minimal skill in parallel computing to implement. We apply this algorithm to make inferences about dynamical models of the growth of a pathogen (baculovirus) population inside a host (gypsy moth, Lymantria dispar). The line-search MCMC appeal rests on its ease of implementation, and its potential for efficiency improvements over classical MCMC in a highly parallel setting, which makes it especially useful for ecological models.},
   author = {David A. Kennedy and Vanja Dukic and Greg Dwyer},
   doi = {10.1007/s10651-014-0297-0},
   issn = {15733009},
   issue = {2},
   journal = {Environmental and Ecological Statistics},
   keywords = {Birth–death model,MCMC,Parameter line-search,Survival-time data,Within-host model},
   month = {6},
   pages = {247-274},
   publisher = {Kluwer Academic Publishers},
   title = {Combining principal component analysis with parameter line-searches to improve the efficacy of Metropolis–Hastings MCMC},
   volume = {22},
   year = {2015},
}
@article{Sengupta2015,
   abstract = {In this technical note we compare the performance of four gradient-free MCMC samplers (random walk Metropolis sampling, slice-sampling, adaptive MCMC sampling and population-based MCMC sampling with tempering) in terms of the number of independent samples they can produce per unit computational time. For the Bayesian inversion of a single-node neural mass model, both adaptive and population-based samplers are more efficient compared with random walk Metropolis sampler or slice-sampling; yet adaptive MCMC sampling is more promising in terms of compute time. Slice-sampling yields the highest number of independent samples from the target density - albeit at almost 1000% increase in computational time, in comparison to the most efficient algorithm (i.e., the adaptive MCMC sampler).},
   author = {Biswa Sengupta and Karl J. Friston and Will D. Penny},
   doi = {10.1016/j.neuroimage.2015.03.008},
   issn = {10959572},
   journal = {NeuroImage},
   month = {5},
   pages = {375-381},
   pmid = {25776212},
   publisher = {Academic Press Inc.},
   title = {Gradient-free MCMC methods for dynamic causal modelling},
   volume = {112},
   year = {2015},
}
@article{Zhang2016,
   abstract = {© 2015 Taylor  &  Francis. An algorithm for sampling from non-log-concave multivariate distributions is proposed, which improves the adaptive rejection Metropolis sampling (ARMS) algorithm by incorporating the hit and run sampling. It is not rare that the ARMS is trapped away from some subspace with significant probability in the support of the multivariate distribution. While the ARMS updates samples only in the directions that are parallel to dimensions, our proposed method, the hit and run ARMS (HARARMS), updates samples in arbitrary directions determined by the hit and run algorithm, which makes it almost not possible to be trapped in any isolated subspaces. The HARARMS performs the same as ARMS in a single dimension while more reliable in multidimensional spaces. Its performance is illustrated by a Bayesian free-knot spline regression example. We showed that it overcomes the well-known ‘lethargy’ property and decisively find the global optimal number and locations of the knots of the spline function.},
   author = {Huaiye Zhang and Yuefeng Wu and Lulu Cheng and Inyoung Kim},
   doi = {10.1080/00949655.2015.1046074},
   issn = {15635163},
   issue = {5},
   journal = {Journal of Statistical Computation and Simulation},
   keywords = {adaptive rejection metropolis sampling,empirical Bayesian method,free-knot splines,hit and run algorithm,regression splines},
   pages = {973-985},
   title = {Hit and run ARMS: adaptive rejection Metropolis sampling with hit and run random direction},
   volume = {86},
   year = {2016},
}
@article{Sohl-Dickstein2016,
   author = {Jascha Sohl-Dickstein and Mayur Mudigonda and Michael R Deweese and Deweese Berkeley Edu},
   journal = {arXiv},
   pages = {1-9},
   title = {Hamiltonian Monte Carlo Without Detailed Balance},
   year = {2016},
}
@article{Conrad2016,
   abstract = {We construct a new framework for accelerating Markov chain Monte Carlo in posterior sampling problems where standard methods are limited by the computational cost of the likelihood, or of numerical models embedded therein. Our approach introduces local approximations of these models into the Metropolis–Hastings kernel, borrowing ideas from deterministic approximation theory, optimization, and experimental design. Previous efforts at integrating approximate models into inference typically sacrifice either the sampler’s exactness or efficiency; our work seeks to address these limitations by exploiting useful convergence characteristics of local approximations. We prove the ergodicity of our approximate Markov chain, showing that it samples asymptotically from the exact posterior distribution of interest. We describe variations of the algorithm that employ either local polynomial approximations or local Gaussian process regressors. Our theoretical results reinforce the key observation underlying this article: when the likelihood has some local regularity, the number of model evaluations per Markov chain Monte Carlo (MCMC) step can be greatly reduced without biasing the Monte Carlo average. Numerical experiments demonstrate multiple order-of-magnitude reductions in the number of forward model evaluations used in representative ordinary differential equation (ODE) and partial differential equation (PDE) inference problems, with both synthetic and real data. Supplementary materials for this article are available online.},
   author = {Patrick R. Conrad and Youssef M. Marzouk and Natesh S. Pillai and Aaron Smith},
   doi = {10.1080/01621459.2015.1096787},
   issn = {1537274X},
   issue = {516},
   journal = {Journal of the American Statistical Association},
   keywords = {Approximation theory,Computer experiments,Emulators,Experimental design,Local approximation,Markov chain Monte Carlo},
   month = {10},
   pages = {1591-1607},
   publisher = {American Statistical Association},
   title = {Accelerating Asymptotically Exact MCMC for Computationally Intensive Models via Local Approximations},
   volume = {111},
   year = {2016},
}
@article{Chkrebtii2016,
   abstract = {The authors present an ingenious probabilistic numerical solver for deterministic differential equations (DEs). The true solution is progressively identified via model interrogations, in a formal framework of Bayesian updating. I have attempted to extend the authors' ideas to stochastic differential equations (SDEs), and discuss two challenges encountered in this endeavor: (i) the nondifferentiability of SDE sample paths, and (ii) the sampling of diffusion bridges, typically required of solutions to the SDE inverse problem.},
   author = {Oksana A. Chkrebtii and David a. Campbell and Ben Calderhead and Mark A. Girolami},
   doi = {10.1214/16-BA1036},
   issn = {19316690},
   issue = {4},
   journal = {Bayesian Analysis},
   keywords = {Diffusion bridge sampling,Probabilistic solution,Stochastic differential equations},
   month = {12},
   pages = {1269-1273},
   publisher = {International Society for Bayesian Analysis},
   title = {Bayesian Solution Uncertainty Quantification for Differential Equations},
   volume = {11},
   year = {2016},
}
@article{Lu2017,
   abstract = {Calibration of terrestrial ecosystem models is important but challenging. Bayesian inference implemented by Markov chain Monte Carlo (MCMC) sampling provides a comprehensive framework to estimate model parameters and associated uncertainties using their posterior distributions. The effectiveness and efficiency of the method strongly depend on the MCMC algorithm used. In this work, a differential evolution adaptive Metropolis (DREAM) algorithm is used to estimate posterior distributions of 21 parameters for the data assimilation linked ecosystem carbon (DALEC) model using 14 years of daily net ecosystem exchange data collected at the Harvard Forest Environmental Measurement Site eddy-flux tower. The calibration of DREAM results in a better model fit and predictive performance compared to the popular adaptive Metropolis (AM) scheme. Moreover, DREAM indicates that two parameters controlling autumn phenology have multiple modes in their posterior distributions while AM only identifies one mode. The application suggests that DREAM is very suitable to calibrate complex terrestrial ecosystem models, where the uncertain parameter size is usually large and existence of local optima is always a concern. In addition, this effort justifies the assumptions of the error model used in Bayesian calibration according to the residual analysis. The result indicates that a heteroscedastic, correlated, Gaussian error model is appropriate for the problem, and the consequent constructed likelihood function can alleviate the underestimation of parameter uncertainty that is usually caused by using uncorrelated error models.},
   author = {Dan Lu and Daniel Ricciuto and Anthony Walker and Cosmin Safta and William Munger},
   doi = {10.5194/bg-14-4295-2017},
   issn = {17264189},
   issue = {18},
   journal = {Biogeosciences},
   month = {9},
   pages = {4295-4314},
   publisher = {Copernicus GmbH},
   title = {Bayesian calibration of terrestrial ecosystem models: A study of advanced Markov chain Monte Carlo methods},
   volume = {14},
   year = {2017},
}
@article{Shockley2018,
   abstract = {Summary Biological models contain many parameters whose values are difficult to measure directly via experimentation and therefore require calibration against experimental data. Markov chain Monte Carlo (MCMC) methods are suitable to estimate multivariate posterior model parameter distributions, but these methods may exhibit slow or premature convergence in high-dimensional search spaces. Here, we present PyDREAM, a Python implementation of the (Multiple-Try) Differential Evolution Adaptive Metropolis [DREAM (ZS) ] algorithm developed byVrugt and ter Braak (2008)andLaloy and Vrugt (2012). PyDREAM achieves excellent performance for complex, parameter-rich models and takes full advantage of distributed computing resources, facilitating parameter inference and uncertainty estimation of CPU-intensive biological models. Availability and implementation PyDREAM is freely available under the GNU GPLv3 license from the Lopez lab GitHub repository at http://github.com/LoLab-VU/PyDREAM. Contact c.lopez@vanderbilt.edu Supplementary informationSupplementary dataare available at Bioinformatics online.},
   author = {Erin M. Shockley and Jasper A. Vrugt and Carlos F. Lopez},
   doi = {10.1093/bioinformatics/btx626},
   issn = {14602059},
   issue = {4},
   journal = {Bioinformatics},
   month = {2},
   pages = {695-697},
   pmid = {29028896},
   publisher = {Oxford University Press},
   title = {PyDREAM: High-dimensional parameter inference for biological models in python},
   volume = {34},
   year = {2018},
}
@article{Monnahan2018,
   abstract = {Statistical inference is a widely-used, powerful tool for learning about natural processes in diverse fields. The statistical software platforms AD Model Builder (ADMB) and Template Model Builder (TMB) are particularly popular in the ecological literature, where they are typically used to perform frequentist inference of complex models. However, both lack capabilities for flexible and efficient Markov chain Monte Carlo (MCMC) integration. Recently, the no-U-turn sampler (NUTS) MCMC algorithm has gained popularity for Bayesian inference through the software Stan because it is efficient for high dimensional, complex hierarchical models. Here, we introduce the R packages adnuts and tmbstan, which provide NUTS sampling in parallel and interactive diagnostics with ShinyStan. The ADMB source code was modified to provide NUTS, while TMB models are linked directly into Stan. We describe the packages, provide case studies demonstrating their use, and contrast performance against Stan. For TMB models, we show how to test the accuracy of the Laplace approximation using NUTS. For complex models, the performance of ADMB and TMB was typically within +/- 50% the speed of Stan. In one TMB case study we found inaccuracies in the Laplace approximation, potentially leading to biased inference. adnuts provides a new method for estimating hierarchical ADMB models which previously were infeasible. TMB users can fit the same model in both frequentist and Bayesian paradigms, including using NUTS to test the validity of the Laplace approximation of the marginal likelihood for arbitrary subsets of parameters. These software developments extend the available statistical methods of the ADMB and TMB user base with no additional effort by the user.},
   author = {Cole C. Monnahan and Kasper Kristensen},
   doi = {10.1371/journal.pone.0197954},
   issn = {19326203},
   issue = {5},
   journal = {PLoS ONE},
   month = {5},
   pmid = {29795657},
   publisher = {Public Library of Science},
   title = {No-U-turn sampling for fast Bayesian inference in ADMB and TMB: Introducing the adnuts and tmbstan R packages},
   volume = {13},
   year = {2018},
}
@article{Rosenbaum2019,
   abstract = {Empirical time series of interacting entities, e.g. species abundances, are highly useful to study ecological mechanisms. Mathematical models are valuable tools to further elucidate those mechanisms and underlying processes. However, obtaining an agreement between model predictions and experimental observations remains a demanding task. As models always abstract from reality one parameter often summarizes several properties. Parameter measurements are performed in additional experiments independent of the ones delivering the time series. Transferring these parameter values to different settings may result in incorrect parametrizations. On top of that, the properties of organisms and thus the respective parameter values may vary considerably. These issues limit the use of a priori model parametrizations. In this study, we present a method suited for a direct estimation of model parameters and their variability from experimental time series data. We combine numerical simulations of a continuous-time dynamical population model with Bayesian inference, using a hierarchical framework that allows for variability of individual parameters. The method is applied to a comprehensive set of time series from a laboratory predator-prey system that features both steady states and cyclic population dynamics. Our model predictions are able to reproduce both steady states and cyclic dynamics of the data. Additionally to the direct estimates of the parameter values, the Bayesian approach also provides their uncertainties. We found that fitting cyclic population dynamics, which contain more information on the process rates than steady states, yields more precise parameter estimates. We detected significant variability among parameters of different time series and identified the variation in the maximum growth rate of the prey as a source for the transition from steady states to cyclic dynamics. By lending more flexibility to the model, our approach facilitates parametrizations and shows more easily which patterns in time series can be explained also by simple models. Applying Bayesian inference and dynamical population models in conjunction may help to quantify the profound variability in organismal properties in nature.},
   author = {Benjamin Rosenbaum and Michael Raatz and Guntram Weithoff and Gregor F. Fussmann and Ursula Gaedke},
   doi = {10.3389/fevo.2018.00234},
   issn = {2296701X},
   issue = {234},
   journal = {Frontiers in Ecology and Evolution},
   keywords = {Bayesian inference,Chemostat experiments,Ordinary differential equation,Parameter estimation,Population dynamics,Predator prey,Time series analysis,Trait variability},
   pages = {1-14},
   title = {Estimating parameters from multiple time series of population dynamics using bayesian inference},
   volume = {6},
   year = {2019},
}
@article{Adams2020,
   abstract = {Well-intentioned environmental management can backfire, causing unforeseen damage. To avoid this, managers and ecologists seek accurate predictions of the ecosystem-wide impacts of interventions, given small and imprecise datasets, which is an incredibly difficult task. We generated and analysed thousands of ecosystem population time series to investigate whether fitted models can aid decision-makers to select interventions. Using these time-series data (sparse and noisy datasets drawn from deterministic Lotka-Volterra systems with two to nine species, of known network structure), dynamic model forecasts of whether a species’ future population will be positively or negatively affected by rapid eradication of another species were correct > 70% of the time. Although 70% correct classifications is only slightly better than an uninformative prediction (50%), this classification accuracy can be feasibly improved by increasing monitoring accuracy and frequency. Our findings suggest that models may not need to produce well-constrained predictions before they can inform decisions that improve environmental outcomes.},
   author = {Matthew P. Adams and Scott A. Sisson and Kate J. Helmstedt and Christopher M. Baker and Matthew H. Holden and Michaela Plein and Jacinta Holloway and Kerrie L. Mengersen and Eve McDonald-Madden},
   doi = {10.1111/ele.13465},
   issn = {14610248},
   issue = {4},
   journal = {Ecology Letters},
   keywords = {Conservation,decision science,ecological forecasting,ecological modelling,food webs,interaction network,population dynamics,predator–prey interactions,prediction,uncertainty propagation},
   month = {4},
   pages = {607-619},
   pmid = {31989772},
   publisher = {Blackwell Publishing Ltd},
   title = {Informing management decisions for ecological networks, using dynamic models calibrated to noisy time-series data},
   volume = {23},
   year = {2020},
}
@article{Huang2020,
   abstract = {We develop a Bayesian approach to estimate the parameters of ordinary differential equations (ODE) from the observed noisy data. Our method does not need to solve ODE directly. We replace the ODE constraint with a probability expression and combine it with the nonparametric data fitting procedure into a joint likelihood framework. One advantage of the proposed method is that for some ODE systems, one can obtain closed form conditional posterior distributions for all variables which substantially reduce the computational cost and facilitate the convergence process. An efficient Riemann manifold based hybrid Monte Carlo scheme is implemented to generate samples for variables whose conditional posterior distribution cannot be written in terms of closed form. Our approach can be applied to situations where the state variables are only partially observed. The usefulness of the proposed method is demonstrated through applications to both simulated and real data.},
   author = {Hanwen Huang and Andreas Handel and Xiao Song},
   doi = {10.1007/s00180-020-00962-8},
   issn = {16139658},
   issue = {3},
   journal = {Computational Statistics},
   keywords = {Hybrid Monte Carlo,Joint likelihood framework,Noisy data,Nonparametric fitting,ODE constraint},
   month = {9},
   pages = {1481-1499},
   publisher = {Springer},
   title = {A Bayesian approach to estimate parameters of ordinary differential equation},
   volume = {35},
   year = {2020},
}
@article{Ponisio2019,
   abstract = {Improved efficiency of Markov chain Monte Carlo facilitates all aspects of statistical analysis with Bayesian hierarchical models. Identifying strategies to improve MCMC performance is becoming increasingly crucial as the complexity of models, and the run times to fit them, increases. We evaluate different strategies for improving MCMC efficiency using the open-source software NIMBLE (R package nimble) using common ecological models of species occurrence and abundance as examples. We ask how MCMC efficiency depends on model formulation, model size, data, and sampling strategy. For multiseason and/or multispecies occupancy models and for N-mixture models, we compare the efficiency of sampling discrete latent states vs. integrating over them, including more vs. fewer hierarchical model components, and univariate vs. block-sampling methods. We include the common MCMC tool JAGS in comparisons. For simple models, there is little practical difference between computational approaches. As model complexity increases, there are strong interactions between model formulation and sampling strategy on MCMC efficiency. There is no one-size-fits-all best strategy, but rather problem-specific best strategies related to model structure and type. In all but the simplest cases, NIMBLE's default or customized performance achieves much higher efficiency than JAGS. In the two most complex examples, NIMBLE was 10–12 times more efficient than JAGS. We find NIMBLE is a valuable tool for many ecologists utilizing Bayesian inference, particularly for complex models where JAGS is prohibitively slow. Our results highlight the need for more guidelines and customizable approaches to fit hierarchical models to ensure practitioners can make the most of occupancy and other hierarchical models. By implementing model-generic MCMC procedures in open-source software, including the NIMBLE extensions for integrating over latent states (implemented in the R package nimbleEcology), we have made progress toward this aim.},
   author = {Lauren C. Ponisio and Perry de Valpine and Nicholas Michaud and Daniel Turek},
   doi = {10.1002/ece3.6053},
   issn = {20457758},
   issue = {5},
   journal = {Ecology and Evolution},
   keywords = {Markov chain Monte Carlo,N-mixture,dynamic occupancy,latent states,multispecies occupancy},
   month = {3},
   pages = {2385-2416},
   publisher = {John Wiley and Sons Ltd},
   title = {One size does not fit all: Customizing MCMC methods for hierarchical models using NIMBLE},
   volume = {10},
   year = {2020},
}
@article{Bonnaffe2021a,
   author = {Willem Bonnaffé and Ben C. Sheldon and Tim Coulson},
   doi = {10.1111/2041-210x.13606},
   issn = {2041-210X},
   journal = {Methods in Ecology and Evolution},
   keywords = {article type,artificial neural networks,dynamics,ecological dynamics,evolutionary dynamics,geber,method,neural ordinary differential equations,ordinary differential equations,prey-predator,research article,time series analysis},
   pages = {1-46},
   title = {Neural ordinary differential equations for ecological and evolutionary time series analysis},
   volume = {2},
   year = {2021},
}
@article{Bonnaffe2022,
   abstract = {1. Inferring ecological interactions is hard because we often lack suitable parametric representations to portray them. Neural ordinary differential equations (NODEs) provide a way of estimating interactions nonparametrically from time series data. NODEs, however, are slow to fit, and inferred interactions have not been truthed. 2. We provide a fast NODE fitting method, Bayesian neural gradient matching (BNGM), which relies on interpolating time series with neural networks, and fitting NODEs to the interpolated dynamics with Bayesian regularisation. We test the accuracy of the approach by inferring ecological interactions in time series generated by an ODE model with known interactions. We also infer interactions in experimentally replicated time series of a microcosm featuring an algae, flagellate, and rotifer population, as well as in the hare and lynx system. 3. Our BNGM approach allows us to cut down the fitting time of NODE systems to only a few seconds. The method provides accurate estimates of ecological interactions in the artificial system, as linear and nonlinear true interactions are estimated with minimal error. In the real systems, dynamics are driven by a mixture of linear and nonlinear ecological interactions, of which only the strongest are consistent across replicates. 4. Overall, NODEs alleviate the need for a mechanistic understanding of interactions, and BNGM alleviates the heavy computational cost. This is a crucial step availing quick NODE fitting, cross-validation, and uncertainty quantification, as well as more objective estimation of interactions, and complex context dependence, than parametric models.},
   author = {Willem Bonnaffé and Tim Coulson},
   journal = {arXiv},
   month = {9},
   pages = {1-57},
   title = {Fast fitting of neural ordinary differential equations by Bayesian neural gradient matching to infer ecological interactions from time series data},
   url = {http://arxiv.org/abs/2209.06184},
   year = {2022},
}
